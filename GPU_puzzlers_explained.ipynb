{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23454034",
   "metadata": {
    "id": "23454034",
    "lines_to_next_cell": 2
   },
   "source": [
    "# GPU Puzzles\n",
    "- by [Sasha Rush](http://rush-nlp.com) - [srush_nlp](https://twitter.com/srush_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ffa5eb",
   "metadata": {
    "id": "09ffa5eb"
   },
   "source": [
    "![](https://github.com/srush/GPU-Puzzles/raw/main/cuda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9064f5c",
   "metadata": {
    "id": "c9064f5c"
   },
   "source": [
    "GPU architectures are critical to machine learning, and seem to be\n",
    "becoming even more important every day. However, you can be an expert\n",
    "in machine learning without ever touching GPU code. It is hard to gain\n",
    "intuition working through abstractions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af993a",
   "metadata": {
    "id": "d4af993a"
   },
   "source": [
    "This notebook is an attempt to teach beginner GPU programming in a\n",
    "completely interactive fashion. Instead of providing text with\n",
    "concepts, it throws you right into coding and building GPU\n",
    "kernels. The exercises use NUMBA which directly maps Python\n",
    "code to CUDA kernels. It looks like Python but is basically\n",
    "identical to writing low-level CUDA code. \n",
    "In a few hours, I think you can go from basics to\n",
    "understanding the real algorithms that power 99% of deep learning\n",
    "today. If you do want to read the manual, it is here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb974c6b",
   "metadata": {
    "id": "cb974c6b"
   },
   "source": [
    "[NUMBA CUDA Guide](https://numba.readthedocs.io/en/stable/cuda/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f5a51",
   "metadata": {
    "id": "783f5a51"
   },
   "source": [
    "I recommend doing these in Colab, as it is easy to get started.  Be\n",
    "sure to make your own copy, turn on GPU mode in the settings (`Runtime / Change runtime type`, then set `Hardware accelerator` to `GPU`), and\n",
    "then get to coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b3805",
   "metadata": {
    "id": "743b3805"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/srush/GPU-Puzzles/blob/main/GPU_puzzlers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044bd802",
   "metadata": {
    "id": "044bd802"
   },
   "source": [
    "(If you are into this style of puzzle, also check out my [Tensor\n",
    "Puzzles](https://github.com/srush/Tensor-Puzzles) for PyTorch.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c078331",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:28.090989Z",
     "iopub.status.busy": "2022-08-07T21:24:28.090509Z",
     "iopub.status.idle": "2022-08-07T21:24:40.218920Z",
     "shell.execute_reply": "2022-08-07T21:24:40.217864Z"
    },
    "id": "4c078331",
    "lines_to_next_cell": 2,
    "outputId": "f3711c44-23da-464b-90fe-b615880d1a14"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq git+https://github.com/chalk-diagrams/planar git+https://github.com/danoneata/chalk@srush-patch-1\n",
    "!wget -q https://github.com/srush/GPU-Puzzles/raw/main/robot.png https://github.com/srush/GPU-Puzzles/raw/main/lib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cba43c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:40.223406Z",
     "iopub.status.busy": "2022-08-07T21:24:40.222945Z",
     "iopub.status.idle": "2022-08-07T21:24:40.697137Z",
     "shell.execute_reply": "2022-08-07T21:24:40.696287Z"
    },
    "id": "53cba43c"
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import warnings\n",
    "from lib import CudaProblem, Coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a82629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:40.701357Z",
     "iopub.status.busy": "2022-08-07T21:24:40.700827Z",
     "iopub.status.idle": "2022-08-07T21:24:40.705366Z",
     "shell.execute_reply": "2022-08-07T21:24:40.704574Z"
    },
    "id": "76a82629",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    action=\"ignore\", category=numba.NumbaPerformanceWarning, module=\"numba\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad1b7a",
   "metadata": {
    "id": "d0ad1b7a",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Puzzle 1: Map\n",
    "\n",
    "Implement a \"kernel\" (GPU function) that adds 10 to each position of vector `a`\n",
    "and stores it in vector `out`.  You have 1 thread per position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbce0d",
   "metadata": {
    "id": "2bcbce0d",
    "lines_to_next_cell": 2
   },
   "source": [
    "**Warning** This code looks like Python but it is really CUDA! You cannot use\n",
    "standard python tools like list comprehensions or ask for Numpy properties\n",
    "like shape or size (if you need the size, it is given as an argument).\n",
    "The puzzles only require doing simple operations, basically\n",
    "+, *, simple array indexing, for loops, and if statements.\n",
    "You are allowed to use local variables. \n",
    "If you get an\n",
    "error it is probably because you did something fancy :). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e1d85",
   "metadata": {
    "id": "cb5e1d85"
   },
   "source": [
    "*Tip: Think of the function `call` as being run 1 time for each thread.\n",
    "The only difference is that `cuda.threadIdx.x` changes each time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_14",
   "metadata": {},
   "source": [
    "##  Puzzle 1: Map - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Implement a kernel that adds 10 to each position of vector `a` and stores the result in `out`.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: GPU Parallel Execution Model\n",
    "\n",
    "**The Fundamental Shift in Thinking:**\n",
    "- **CPU**: Write a loop that processes elements one-by-one\n",
    "- **GPU**: Write code for ONE element, run it on THOUSANDS of threads simultaneously\n",
    "\n",
    "```\n",
    "CPU Sequential:                    GPU Parallel:\n",
    "┌─────────────────────┐           ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐\n",
    "│ for i in range(4):  │           │ T0  │ │ T1  │ │ T2  │ │ T3  │\n",
    "│   out[i]=a[i]+10    │           │out[0]│ │out[1]│ │out[2]│ │out[3]│\n",
    "│ (4 sequential ops)  │           └─────┘ └─────┘ └─────┘ └─────┘\n",
    "└─────────────────────┘              └───────────┬───────────┘\n",
    "                                         ALL AT ONCE\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Line-by-Line Deep Analysis\n",
    "\n",
    "#### `local_i = cuda.threadIdx.x`\n",
    "\n",
    "**What is threadIdx.x?**\n",
    "Every CUDA thread has a built-in 3D identifier: `(threadIdx.x, threadIdx.y, threadIdx.z)`. For 1D arrays, we use only `.x`.\n",
    "\n",
    "```\n",
    "When kernel launches with 4 threads:\n",
    "\n",
    "Thread 0: cuda.threadIdx.x == 0\n",
    "Thread 1: cuda.threadIdx.x == 1  \n",
    "Thread 2: cuda.threadIdx.x == 2\n",
    "Thread 3: cuda.threadIdx.x == 3\n",
    "\n",
    "This is AUTOMATIC - you don't set it, you READ it.\n",
    "It's how each thread knows \"I am thread #N\"\n",
    "```\n",
    "\n",
    "#### `out[local_i] = a[local_i] + 10`\n",
    "\n",
    "Each thread:\n",
    "1. **Reads** from global memory: `a[local_i]`\n",
    "2. **Computes**: adds 10\n",
    "3. **Writes** to global memory: `out[local_i]`\n",
    "\n",
    "---\n",
    "\n",
    "###  Complete Execution Trace\n",
    "\n",
    "```\n",
    "Configuration: SIZE=4, a=[0,1,2,3]\n",
    "\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║                    PARALLEL EXECUTION                           ║\n",
    "║            All 4 threads execute SIMULTANEOUSLY                 ║\n",
    "╠════════════════════════════════════════════════════════════════╣\n",
    "║                                                                 ║\n",
    "║  THREAD 0                      THREAD 1                        ║\n",
    "║  ┌──────────────────────┐     ┌──────────────────────┐        ║\n",
    "║  │ threadIdx.x = 0      │     │ threadIdx.x = 1      │        ║\n",
    "║  │ local_i = 0          │     │ local_i = 1          │        ║\n",
    "║  │                      │     │                      │        ║\n",
    "║  │ 1. Read a[0] → 0     │     │ 1. Read a[1] → 1     │        ║\n",
    "║  │ 2. Compute 0+10=10   │     │ 2. Compute 1+10=11   │        ║\n",
    "║  │ 3. Write out[0]=10   │     │ 3. Write out[1]=11   │        ║\n",
    "║  └──────────────────────┘     └──────────────────────┘        ║\n",
    "║                                                                 ║\n",
    "║  THREAD 2                      THREAD 3                        ║\n",
    "║  ┌──────────────────────┐     ┌──────────────────────┐        ║\n",
    "║  │ threadIdx.x = 2      │     │ threadIdx.x = 3      │        ║\n",
    "║  │ local_i = 2          │     │ local_i = 3          │        ║\n",
    "║  │                      │     │                      │        ║\n",
    "║  │ 1. Read a[2] → 2     │     │ 1. Read a[3] → 3     │        ║\n",
    "║  │ 2. Compute 2+10=12   │     │ 2. Compute 3+10=13   │        ║\n",
    "║  │ 3. Write out[2]=12   │     │ 3. Write out[3]=13   │        ║\n",
    "║  └──────────────────────┘     └──────────────────────┘        ║\n",
    "║                                                                 ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "RESULT: out = [10, 11, 12, 13]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Insight: Same Code, Different Data\n",
    "\n",
    "```python\n",
    "# This is the SAME code that ALL threads run:\n",
    "local_i = cuda.threadIdx.x\n",
    "out[local_i] = a[local_i] + 10\n",
    "\n",
    "# But each thread gets a DIFFERENT value for threadIdx.x!\n",
    "# That's what makes it parallel.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Memory Access Pattern: Coalesced Access\n",
    "\n",
    "When adjacent threads access adjacent memory addresses, GPU can combine these into efficient bulk transfers:\n",
    "\n",
    "```\n",
    "Coalesced (GOOD):          Non-coalesced (BAD):\n",
    "T0→a[0] T1→a[1] T2→a[2]    T0→a[0] T1→a[7] T2→a[3]\n",
    "    ↓                           ↓\n",
    "ONE memory transaction      MULTIPLE transactions\n",
    "```\n",
    "\n",
    "Our solution is perfectly coalesced!\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **threadIdx.x** = unique ID for each thread (0 to N-1)\n",
    "2. **Write code for ONE thread** - GPU runs it on all threads\n",
    "3. **Use thread ID as array index** - creates the parallelism\n",
    "4. **No loops needed** - parallelism replaces iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0899de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:40.710192Z",
     "iopub.status.busy": "2022-08-07T21:24:40.709745Z",
     "iopub.status.idle": "2022-08-07T21:24:40.779921Z",
     "shell.execute_reply": "2022-08-07T21:24:40.779104Z"
    },
    "id": "ab0899de",
    "outputId": "a98a5828-bf1d-402f-dd61-68cfe9b69d9d"
   },
   "outputs": [],
   "source": [
    "def map_spec(a):\n",
    "    return a + 10\n",
    "\n",
    "\n",
    "def map_test(cuda):\n",
    "    def call(out, a) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        out[local_i] = a[local_i] + 10\n",
    "        \n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Map\", map_test, [a], out, threadsperblock=Coord(SIZE, 1), spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5520a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:40.783843Z",
     "iopub.status.busy": "2022-08-07T21:24:40.783394Z",
     "iopub.status.idle": "2022-08-07T21:24:41.318965Z",
     "shell.execute_reply": "2022-08-07T21:24:41.318117Z"
    },
    "id": "0a5520a6",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "d3f1e273-d5e0-4e4b-ccaf-fd28840f899f"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aecc28",
   "metadata": {
    "id": "59aecc28"
   },
   "source": [
    "## Puzzle 2 - Zip\n",
    "\n",
    "Implement a kernel that adds together each position of `a` and `b` and stores it in `out`.\n",
    "You have 1 thread per position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_17",
   "metadata": {},
   "source": [
    "##  Puzzle 2: Zip - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Add corresponding elements of vectors `a` and `b`, store in `out`: `out[i] = a[i] + b[i]`\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Element-wise Operations\n",
    "\n",
    "This is the most common GPU pattern - each output depends only on inputs at the same index.\n",
    "\n",
    "```\n",
    "a = [0, 1, 2, 3]\n",
    "    +  +  +  +   (element-wise)\n",
    "b = [0, 1, 2, 3]\n",
    "    =  =  =  =\n",
    "out=[0, 2, 4, 6]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Thread Execution Trace\n",
    "\n",
    "```\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║  Thread 0                      Thread 1                        ║\n",
    "║  ┌──────────────────────┐     ┌──────────────────────┐        ║\n",
    "║  │ Read a[0] → 0        │     │ Read a[1] → 1        │        ║\n",
    "║  │ Read b[0] → 0        │     │ Read b[1] → 1        │        ║\n",
    "║  │ Compute: 0+0=0       │     │ Compute: 1+1=2       │        ║\n",
    "║  │ Write out[0]=0       │     │ Write out[1]=2       │        ║\n",
    "║  └──────────────────────┘     └──────────────────────┘        ║\n",
    "║                                                                 ║\n",
    "║  Thread 2                      Thread 3                        ║\n",
    "║  ┌──────────────────────┐     ┌──────────────────────┐        ║\n",
    "║  │ Read a[2] → 2        │     │ Read a[3] → 3        │        ║\n",
    "║  │ Read b[2] → 2        │     │ Read b[3] → 3        │        ║\n",
    "║  │ Compute: 2+2=4       │     │ Compute: 3+3=6       │        ║\n",
    "║  │ Write out[2]=4       │     │ Write out[3]=6       │        ║\n",
    "║  └──────────────────────┘     └──────────────────────┘        ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Why No Synchronization Needed?\n",
    "\n",
    "Each thread operates on completely independent data:\n",
    "- Thread 0 only touches index 0\n",
    "- Thread 1 only touches index 1\n",
    "- No thread reads what another writes\n",
    "\n",
    "**No data dependencies = no synchronization required!**\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Same index pattern** - Thread i accesses index i in ALL arrays\n",
    "2. **Multiple reads, one write** - Can read from many arrays, write to one\n",
    "3. **Perfect parallelism** - Threads are 100% independent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b4208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.322974Z",
     "iopub.status.busy": "2022-08-07T21:24:41.322540Z",
     "iopub.status.idle": "2022-08-07T21:24:41.408046Z",
     "shell.execute_reply": "2022-08-07T21:24:41.407300Z"
    },
    "id": "619b4208",
    "lines_to_next_cell": 0,
    "outputId": "9c06a417-9d69-4787-ca33-3c222496053e"
   },
   "outputs": [],
   "source": [
    "from threading import local\n",
    "\n",
    "\n",
    "def zip_spec(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def zip_test(cuda):\n",
    "    def call(out, a, b) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        out[local_i]=a[local_i]+b[local_i]\n",
    "\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Zip\", zip_test, [a, b], out, threadsperblock=Coord(SIZE, 1), spec=zip_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5037564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.411997Z",
     "iopub.status.busy": "2022-08-07T21:24:41.411569Z",
     "iopub.status.idle": "2022-08-07T21:24:41.450428Z",
     "shell.execute_reply": "2022-08-07T21:24:41.449609Z"
    },
    "id": "f5037564",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "22798fcf-0f3c-47a0-98c5-dbe671f25f57"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90ab5b",
   "metadata": {
    "id": "bb90ab5b"
   },
   "source": [
    "## Puzzle 3 - Guards\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have more threads than positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_20",
   "metadata": {},
   "source": [
    "##  Puzzle 3: Guards - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Add 10 to each element of `a`, but handle the case where **more threads are launched than data elements exist**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Why Guards Are Essential\n",
    "\n",
    "```\n",
    "The Problem:\n",
    "├── Array size:    4 elements (indices 0,1,2,3)\n",
    "├── Threads:       8 threads (indices 0,1,2,3,4,5,6,7)\n",
    "└── Extra threads: 4 threads that have NO DATA to work on!\n",
    "\n",
    "WITHOUT guard:\n",
    "Thread 4 executes: out[4] = a[4] + 10\n",
    "                        ↓\n",
    "                   a[4] DOESN'T EXIST! \n",
    "                   → Undefined behavior\n",
    "                   → Crash or memory corruption\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Guard Condition Execution\n",
    "\n",
    "```\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║                    THE GUARD IN ACTION                          ║\n",
    "╠════════════════════════════════════════════════════════════════╣\n",
    "║                                                                 ║\n",
    "║  Thread 0: local_i=0   0 < 4 ?  YES  → out[0]=a[0]+10        ║\n",
    "║  Thread 1: local_i=1   1 < 4 ?  YES  → out[1]=a[1]+10        ║\n",
    "║  Thread 2: local_i=2   2 < 4 ?  YES  → out[2]=a[2]+10        ║\n",
    "║  Thread 3: local_i=3   3 < 4 ?  YES  → out[3]=a[3]+10        ║\n",
    "║  ─────────────────────────────────────────────────────────────  ║\n",
    "║  Thread 4: local_i=4   4 < 4 ?  NO   → (does nothing)        ║\n",
    "║  Thread 5: local_i=5   5 < 4 ?  NO   → (does nothing)        ║\n",
    "║  Thread 6: local_i=6   6 < 4 ?  NO   → (does nothing)        ║\n",
    "║  Thread 7: local_i=7   7 < 4 ?  NO   → (does nothing)        ║\n",
    "║                                                                 ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  What Happens Without a Guard?\n",
    "\n",
    "```\n",
    "Memory layout:\n",
    "\n",
    "Valid memory:        Invalid (unallocated):\n",
    "a[0] a[1] a[2] a[3]  ??? ??? ??? ???\n",
    " ↑    ↑    ↑    ↑     ↑   ↑   ↑   ↑\n",
    "T0   T1   T2   T3    T4  T5  T6  T7 (try to access)\n",
    "                      ↓\n",
    "              UNDEFINED BEHAVIOR:\n",
    "              • Read garbage\n",
    "              • Crash\n",
    "              • Corrupt other data\n",
    "              • Wrong results\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **ALWAYS use guards** - Even if you think sizes match\n",
    "2. **Pass size as parameter** - Kernel needs boundary information\n",
    "3. **Guard before array access** - `if idx < size:` then access\n",
    "4. **Guards are cheap** - One comparison saves crashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c83704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.454648Z",
     "iopub.status.busy": "2022-08-07T21:24:41.454179Z",
     "iopub.status.idle": "2022-08-07T21:24:41.527083Z",
     "shell.execute_reply": "2022-08-07T21:24:41.526268Z"
    },
    "id": "f5c83704",
    "outputId": "2ca047fc-ab05-43f6-e13c-bf0c5504a54a"
   },
   "outputs": [],
   "source": [
    "def map_guard_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        for i in range(size):\n",
    "            out[i]=a[i]+10\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Guard\",\n",
    "    map_guard_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(8, 1),\n",
    "    spec=map_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34629f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.530990Z",
     "iopub.status.busy": "2022-08-07T21:24:41.530541Z",
     "iopub.status.idle": "2022-08-07T21:24:41.561067Z",
     "shell.execute_reply": "2022-08-07T21:24:41.560144Z"
    },
    "id": "2e34629f",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "4624d5c3-436e-4a3b-d532-c67538ed40e0"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33ed08",
   "metadata": {
    "id": "ec33ed08"
   },
   "source": [
    "## Puzzle 4 - Map 2D\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "Input `a` is 2D and square. You have more threads than positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_23",
   "metadata": {},
   "source": [
    "##  Puzzle 4: Map 2D - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Add 10 to each element of a 2D matrix using 2D thread indexing.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: 2D Thread Organization\n",
    "\n",
    "```\n",
    "2D Thread Block (3×3):\n",
    "\n",
    "           threadIdx.x (row)\n",
    "              0     1     2\n",
    "           ┌─────┬─────┬─────┐\n",
    "         0 │(0,0)│(1,0)│(2,0)│\n",
    "threadIdx  ├─────┼─────┼─────┤\n",
    "   .y    1 │(0,1)│(1,1)│(2,1)│\n",
    "(column)   ├─────┼─────┼─────┤\n",
    "         2 │(0,2)│(1,2)│(2,2)│\n",
    "           └─────┴─────┴─────┘\n",
    "\n",
    "Each thread has TWO coordinates: (threadIdx.x, threadIdx.y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Thread-to-Matrix Mapping\n",
    "\n",
    "```\n",
    "2×2 Matrix:              3×3 Thread Block:\n",
    "┌────┬────┐             ┌─────┬─────┬─────┐\n",
    "│a00 │a01 │             │T(0,0)│T(1,0)│T(2,0)│ ←Row 2 GUARDED\n",
    "├────┼────┤             ├─────┼─────┼─────┤\n",
    "│a10 │a11 │             │T(0,1)│T(1,1)│T(2,1)│ ←Row 2 GUARDED\n",
    "└────┴────┘             ├─────┼─────┼─────┤\n",
    "                        │T(0,2)│T(1,2)│T(2,2)│ ←ALL GUARDED\n",
    "                        └─────┴─────┴─────┘\n",
    "                              ↑\n",
    "                           Col 2 GUARDED\n",
    "\n",
    "Active: T(0,0), T(1,0), T(0,1), T(1,1) = 4 threads\n",
    "Guarded: 5 threads (where i≥2 OR j≥2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Why Guard BOTH Dimensions?\n",
    "\n",
    "```python\n",
    "if local_i < size and local_j < size:\n",
    "```\n",
    "\n",
    "Thread (2,0): `local_i=2, local_j=0`\n",
    "- Check `local_i < 2`: 2 < 2 → FALSE → Correctly guarded\n",
    "\n",
    "Thread (0,2): `local_i=0, local_j=2`  \n",
    "- Check `local_j < 2`: 2 < 2 → FALSE → Correctly guarded\n",
    "\n",
    "If we only checked ONE dimension, we'd miss the other!\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **threadIdx.x for rows, threadIdx.y for columns** (or vice versa, be consistent!)\n",
    "2. **Guard BOTH dimensions**: `if i < size and j < size`\n",
    "3. **9 threads for 4 elements = 5 idle threads** - that's OK!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5eff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.565190Z",
     "iopub.status.busy": "2022-08-07T21:24:41.564731Z",
     "iopub.status.idle": "2022-08-07T21:24:41.639943Z",
     "shell.execute_reply": "2022-08-07T21:24:41.639094Z"
    },
    "id": "75d5eff5",
    "outputId": "358b8e1c-5601-4a90-d1f0-2bfbbff26b9b"
   },
   "outputs": [],
   "source": [
    "def map_2D_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                out[i,j]=a[i,j]+10\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "problem = CudaProblem(\n",
    "    \"Map 2D\", map_2D_test, [a], out, [SIZE], threadsperblock=Coord(3, 3), spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed777631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.643707Z",
     "iopub.status.busy": "2022-08-07T21:24:41.643280Z",
     "iopub.status.idle": "2022-08-07T21:24:41.675212Z",
     "shell.execute_reply": "2022-08-07T21:24:41.674350Z"
    },
    "id": "ed777631",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "8ae847a3-fc31-44a3-c9c3-b669e796ac67"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfd649",
   "metadata": {
    "id": "bdcfd649"
   },
   "source": [
    "## Puzzle 5 - Broadcast\n",
    "\n",
    "Implement a kernel that adds `a` and `b` and stores it in `out`.\n",
    "Inputs `a` and `b` are vectors. You have more threads than positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_26",
   "metadata": {},
   "source": [
    "##  Puzzle 5: Broadcast - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Add a column vector and row vector using broadcasting to produce a 2D matrix.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Broadcasting\n",
    "\n",
    "Broadcasting \"stretches\" arrays to match shapes:\n",
    "\n",
    "```\n",
    "Column a (2×1):    Row b (1×2):       Result (2×2):\n",
    "    ┌───┐          ┌───┬───┐         ┌─────────┬─────────┐\n",
    "    │ 0 │    +     │ 0 │ 1 │    =    │ 0+0 = 0 │ 0+1 = 1 │\n",
    "    ├───┤          └───┴───┘         ├─────────┼─────────┤\n",
    "    │ 1 │                            │ 1+0 = 1 │ 1+1 = 2 │\n",
    "    └───┘                            └─────────┴─────────┘\n",
    "    \n",
    "Column \"repeats\"   Row \"repeats\"\n",
    "horizontally       vertically\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  The Key Insight: Index Patterns\n",
    "\n",
    "```python\n",
    "a[local_i, 0]   # Row varies (local_i), Column FIXED at 0\n",
    "b[0, local_j]   # Row FIXED at 0, Column varies (local_j)\n",
    "\n",
    "Thread (0,0): a[0,0] + b[0,0] = 0 + 0 = 0\n",
    "Thread (1,0): a[1,0] + b[0,0] = 1 + 0 = 1  ← Different row of a\n",
    "Thread (0,1): a[0,0] + b[0,1] = 0 + 1 = 1  ← Different col of b\n",
    "Thread (1,1): a[1,0] + b[0,1] = 1 + 1 = 2  ← Both different\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Data Reuse Pattern\n",
    "\n",
    "```\n",
    "a[0,0] is read by: Thread(0,0), Thread(0,1)  ← Entire column of threads\n",
    "a[1,0] is read by: Thread(1,0), Thread(1,1)  ← Entire column of threads\n",
    "b[0,0] is read by: Thread(0,0), Thread(1,0)  ← Entire row of threads\n",
    "b[0,1] is read by: Thread(0,1), Thread(1,1)  ← Entire row of threads\n",
    "\n",
    "Each element is read multiple times - opportunity for shared memory!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Fix one index, vary the other** - Creates the broadcast pattern\n",
    "2. **Column vector**: `a[row, 0]` - column always 0\n",
    "3. **Row vector**: `b[0, col]` - row always 0\n",
    "4. **Same data read by multiple threads** - Optimization opportunity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e664b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.679242Z",
     "iopub.status.busy": "2022-08-07T21:24:41.678801Z",
     "iopub.status.idle": "2022-08-07T21:24:41.759781Z",
     "shell.execute_reply": "2022-08-07T21:24:41.758930Z"
    },
    "id": "123e664b",
    "outputId": "9b16e7be-3978-4d06-8427-2d2595fbe6d7"
   },
   "outputs": [],
   "source": [
    "def broadcast_test(cuda):\n",
    "    def call(out, a, b, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                out[i,j]=a[i,0]+b[0,j]\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.arange(SIZE).reshape(SIZE, 1)\n",
    "b = np.arange(SIZE).reshape(1, SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Broadcast\",\n",
    "    broadcast_test,\n",
    "    [a, b],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(3, 3),\n",
    "    spec=zip_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25686b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.763601Z",
     "iopub.status.busy": "2022-08-07T21:24:41.763153Z",
     "iopub.status.idle": "2022-08-07T21:24:41.798938Z",
     "shell.execute_reply": "2022-08-07T21:24:41.798139Z"
    },
    "id": "f25686b3",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "02eb386e-4493-4028-bb78-5543c11e4a45"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3173e",
   "metadata": {
    "id": "e9c3173e"
   },
   "source": [
    "## Puzzle 6 - Blocks\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have fewer threads per block than the size of `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3affc",
   "metadata": {
    "id": "9dd3affc"
   },
   "source": [
    "*Tip: A block is a group of threads. The number of threads per block is limited, but we can\n",
    "have many different blocks. Variable `cuda.blockIdx` tells us what block we are in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_30",
   "metadata": {},
   "source": [
    "##  Puzzle 6: Blocks - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Add 10 to each element using MULTIPLE BLOCKS for arrays larger than one block.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Block Hierarchy\n",
    "\n",
    "```\n",
    "Grid (all blocks):\n",
    "┌─────────────┬─────────────┬─────────────┐\n",
    "│  BLOCK 0    │  BLOCK 1    │  BLOCK 2    │\n",
    "│ blockIdx=0  │ blockIdx=1  │ blockIdx=2  │\n",
    "├─────────────┼─────────────┼─────────────┤\n",
    "│ T0 T1 T2 T3 │ T0 T1 T2 T3 │ T0 T1 T2 T3 │\n",
    "└─────────────┴─────────────┴─────────────┘\n",
    "  handles       handles       handles\n",
    "  a[0:4]        a[4:8]        a[8:9]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  The Global Index Formula\n",
    "\n",
    "```\n",
    "i = blockIdx.x * blockDim.x + threadIdx.x\n",
    "\n",
    "Example: blockDim=4, 3 blocks\n",
    "\n",
    "Block 0 (blockIdx.x = 0):\n",
    "  T0: i = 0*4 + 0 = 0\n",
    "  T1: i = 0*4 + 1 = 1\n",
    "  T2: i = 0*4 + 2 = 2\n",
    "  T3: i = 0*4 + 3 = 3\n",
    "\n",
    "Block 1 (blockIdx.x = 1):\n",
    "  T0: i = 1*4 + 0 = 4\n",
    "  T1: i = 1*4 + 1 = 5\n",
    "  T2: i = 1*4 + 2 = 6\n",
    "  T3: i = 1*4 + 3 = 7\n",
    "\n",
    "Block 2 (blockIdx.x = 2):\n",
    "  T0: i = 2*4 + 0 = 8  ← Valid (8 < 9)\n",
    "  T1: i = 2*4 + 1 = 9  ← GUARDED (9 ≥ 9)\n",
    "  T2: i = 2*4 + 2 = 10 ← GUARDED\n",
    "  T3: i = 2*4 + 3 = 11 ← GUARDED\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Visual Mapping\n",
    "\n",
    "```\n",
    "Array:    [0] [1] [2] [3] [4] [5] [6] [7] [8]\n",
    "           │   │   │   │   │   │   │   │   │\n",
    "Thread:   T0  T1  T2  T3  T0  T1  T2  T3  T0\n",
    "Block:    └─── Block 0 ───┘ └─── Block 1 ───┘ └─ Block 2 ─┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Global index**: `blockIdx.x * blockDim.x + threadIdx.x`\n",
    "2. **Blocks are independent** - Cannot communicate directly\n",
    "3. **Always guard** - Last block often has extra threads\n",
    "4. **Formula for # blocks**: `(size + blockDim - 1) // blockDim`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a6755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.803000Z",
     "iopub.status.busy": "2022-08-07T21:24:41.802566Z",
     "iopub.status.idle": "2022-08-07T21:24:41.980798Z",
     "shell.execute_reply": "2022-08-07T21:24:41.979932Z"
    },
    "id": "6e0a6755",
    "outputId": "4a015cc3-be75-443c-f7ec-acc6f3fe97cf"
   },
   "outputs": [],
   "source": [
    "def map_block_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        if i < size:\n",
    "            out[i] = a[i] + 10\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 9\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Blocks\",\n",
    "    map_block_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(4, 1),\n",
    "    blockspergrid=Coord(3, 1),\n",
    "    spec=map_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02498f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:41.985202Z",
     "iopub.status.busy": "2022-08-07T21:24:41.984759Z",
     "iopub.status.idle": "2022-08-07T21:24:42.023573Z",
     "shell.execute_reply": "2022-08-07T21:24:42.022706Z"
    },
    "id": "6c02498f",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "035a3ff2-4727-48f7-8459-05c279539676"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1871a41",
   "metadata": {
    "id": "e1871a41"
   },
   "source": [
    "## Puzzle 7 - Blocks 2D\n",
    "\n",
    "Implement the same kernel in 2D.  You have fewer threads per block\n",
    "than the size of `a` in both directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_33",
   "metadata": {},
   "source": [
    "##  Puzzle 7: Blocks 2D - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement  \n",
    "Add 10 to each element of a 2D matrix using 2D blocks.\n",
    "\n",
    "---\n",
    "\n",
    "###  2D Index Calculation\n",
    "\n",
    "Same formula, applied to BOTH dimensions:\n",
    "\n",
    "```\n",
    "Row:    i = blockIdx.x * blockDim.x + threadIdx.x\n",
    "Column: j = blockIdx.y * blockDim.y + threadIdx.y\n",
    "\n",
    "Example: 5×5 matrix, 3×3 blocks, 2×2 grid\n",
    "\n",
    "Block (1,1), Thread (1,0):\n",
    "  i = 1*3 + 1 = 4\n",
    "  j = 1*3 + 0 = 3\n",
    "  → handles element a[4,3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Block Coverage\n",
    "\n",
    "```\n",
    "         Columns 0-2      Columns 3-5\n",
    "        (blockIdx.y=0)   (blockIdx.y=1)\n",
    "       ┌──────────────┬──────────────┐\n",
    "       │  Block(0,0)  │  Block(0,1)  │ Rows 0-2\n",
    "       │   9 threads  │  6 active    │ (blockIdx.x=0)\n",
    "       ├──────────────┼──────────────┤\n",
    "       │  Block(1,0)  │  Block(1,1)  │ Rows 3-5\n",
    "       │  6 active    │  4 active    │ (blockIdx.x=1)\n",
    "       └──────────────┴──────────────┘\n",
    "                       \n",
    "36 total threads, 25 active, 11 guarded\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Same formula for each dimension**\n",
    "2. **2D grid of 2D blocks** - Natural for matrices\n",
    "3. **Guard both dimensions**: `if i < size and j < size`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4f1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:42.027634Z",
     "iopub.status.busy": "2022-08-07T21:24:42.027201Z",
     "iopub.status.idle": "2022-08-07T21:24:42.601813Z",
     "shell.execute_reply": "2022-08-07T21:24:42.600919Z"
    },
    "id": "8ff4f1b6",
    "outputId": "fe385739-6622-4d36-f267-fae8b5bd6cc6"
   },
   "outputs": [],
   "source": [
    "def map_block2D_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        if i < size and j < size:\n",
    "            out[i,j]=a[i,j]+10\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 5\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.ones((SIZE, SIZE))\n",
    "\n",
    "problem = CudaProblem(\n",
    "    \"Blocks 2D\",\n",
    "    map_block2D_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(3, 3),\n",
    "    blockspergrid=Coord(2, 2),\n",
    "    spec=map_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485a106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:42.608019Z",
     "iopub.status.busy": "2022-08-07T21:24:42.607554Z",
     "iopub.status.idle": "2022-08-07T21:24:42.645410Z",
     "shell.execute_reply": "2022-08-07T21:24:42.644607Z"
    },
    "id": "e485a106",
    "outputId": "959b7abb-b97a-43a0-998b-6ded7d92879f"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031ed95",
   "metadata": {
    "id": "4031ed95"
   },
   "source": [
    "## Puzzle 8 - Shared\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have fewer threads per block than the size of `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df50159",
   "metadata": {
    "id": "2df50159"
   },
   "source": [
    "**Warning**: Each block can only have a *constant* amount of shared\n",
    " memory that threads in that block can read and write to. This needs\n",
    " to be a literal python constant not a variable. After writing to\n",
    " shared memory you need to call `cuda.syncthreads` to ensure that\n",
    " threads do not cross."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a21b0",
   "metadata": {
    "id": "9b4a21b0"
   },
   "source": [
    "(This example does not really need shared memory or syncthreads, but it is a demo.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_38",
   "metadata": {},
   "source": [
    "##  Puzzle 8: Shared Memory - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Use shared memory to load data cooperatively before computing.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Memory Hierarchy\n",
    "\n",
    "```\n",
    "Speed:  Registers > Shared Memory > Global Memory\n",
    "           ↑            ↑              ↑\n",
    "        ~1 cycle     ~5 cycles    ~400 cycles\n",
    "\n",
    "Shared memory is ~100x faster than global memory!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Why syncthreads() Is Critical\n",
    "\n",
    "```\n",
    "WITHOUT syncthreads():\n",
    "\n",
    "Thread 0: shared[0]=a[0] ─────────────── val=shared[0] ────→\n",
    "Thread 1: ───────────── shared[1]=a[1] ──────────── val=shared[1]\n",
    "Thread 2: shared[2]=a[2] ── val=shared[2] ←─ DANGER! Thread 2 \n",
    "                                             might read before\n",
    "                                             Thread 2 writes!\n",
    "\n",
    "WITH syncthreads():\n",
    "\n",
    "Thread 0: shared[0]=a[0] ─┐\n",
    "Thread 1: shared[1]=a[1] ─┼──BARRIER──┬─ val=shared[0]\n",
    "Thread 2: shared[2]=a[2] ─┤   wait    ├─ val=shared[1]\n",
    "Thread 3: shared[3]=a[3] ─┘   here    └─ val=shared[2]\n",
    "\n",
    "ALL writes complete before ANY reads!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Execution Trace\n",
    "\n",
    "```\n",
    "Block 0:\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│ PHASE 1: Cooperative Load (all threads work in parallel)       │\n",
    "│                                                                 │\n",
    "│   T0: shared[0] = a[0]    T2: shared[2] = a[2]                │\n",
    "│   T1: shared[1] = a[1]    T3: shared[3] = a[3]                │\n",
    "│                                                                 │\n",
    "│   shared[] = [a[0], a[1], a[2], a[3]]                         │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│ syncthreads() - ALL threads wait here                          │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│ PHASE 2: Compute (all threads read their element)              │\n",
    "│                                                                 │\n",
    "│   T0: val=shared[0], out[0]=val+10                            │\n",
    "│   T1: val=shared[1], out[1]=val+10                            │\n",
    "│   T2: val=shared[2], out[2]=val+10                            │\n",
    "│   T3: val=shared[3], out[3]=val+10                            │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Properties of Shared Memory\n",
    "\n",
    "```\n",
    "1. PER-BLOCK: Each block has its own separate shared memory\n",
    "   Block 0: shared[] = [_, _, _, _]\n",
    "   Block 1: shared[] = [_, _, _, _]  ← Different array!\n",
    "\n",
    "2. LIMITED SIZE: ~48KB per block (varies by GPU)\n",
    "\n",
    "3. REQUIRES SYNC: Must use syncthreads() between write and read phases\n",
    "\n",
    "4. DECLARED STATICALLY: Size must be known at compile time\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Shared memory is fast** - Use it for data accessed multiple times\n",
    "2. **syncthreads() is mandatory** - Prevents race conditions\n",
    "3. **Each block has separate shared memory** - No cross-block sharing\n",
    "4. **Pattern: Load → Sync → Compute → Sync (if needed) → Store**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62213ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:42.649928Z",
     "iopub.status.busy": "2022-08-07T21:24:42.649199Z",
     "iopub.status.idle": "2022-08-07T21:24:42.854066Z",
     "shell.execute_reply": "2022-08-07T21:24:42.853252Z"
    },
    "id": "62213ea0",
    "outputId": "1810c168-9304-4d6f-d248-33f0a4d3d56a"
   },
   "outputs": [],
   "source": [
    "TPB = 4\n",
    "def shared_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        shared = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "\n",
    "        if i < size:\n",
    "            shared[local_i] = a[i]\n",
    "            cuda.syncthreads()\n",
    "\n",
    "            val = shared[local_i]\n",
    "            out[i]=val+10\n",
    "        \n",
    "\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 8\n",
    "out = np.zeros(SIZE)\n",
    "a = np.ones(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Shared\",\n",
    "    shared_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(TPB, 1),\n",
    "    blockspergrid=Coord(2, 1),\n",
    "    spec=map_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193e0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:42.858447Z",
     "iopub.status.busy": "2022-08-07T21:24:42.858006Z",
     "iopub.status.idle": "2022-08-07T21:24:42.926443Z",
     "shell.execute_reply": "2022-08-07T21:24:42.925655Z"
    },
    "id": "6193e0ea",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "a9758ec9-b59e-48ec-d92b-ed5d4f23e57b"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee2ee",
   "metadata": {
    "id": "815ee2ee"
   },
   "source": [
    "## Puzzle 9 - Pooling\n",
    "\n",
    "Implement a kernel that sums together the last 3 position of `a` and stores it in `out`.\n",
    "You have 1 thread per position. You only need 1 global read and 1 global write per thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947cff1",
   "metadata": {
    "id": "9947cff1"
   },
   "source": [
    "*Tip: Remember to be careful about syncing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_42",
   "metadata": {},
   "source": [
    "##  Puzzle 9: Pooling - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Compute sliding window sum: `out[i] = a[i] + a[i-1] + a[i-2]` (where indices exist)\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Neighbor Access Pattern\n",
    "\n",
    "Each output needs MULTIPLE input values - not just its own index!\n",
    "\n",
    "```\n",
    "Input:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "out[0] = a[0]                    = 0\n",
    "out[1] = a[0] + a[1]             = 0 + 1 = 1\n",
    "out[2] = a[0] + a[1] + a[2]      = 0 + 1 + 2 = 3\n",
    "out[3] = a[1] + a[2] + a[3]      = 1 + 2 + 3 = 6\n",
    "out[4] = a[2] + a[3] + a[4]      = 2 + 3 + 4 = 9\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Why Shared Memory Matters Here\n",
    "\n",
    "```\n",
    "Without shared memory:\n",
    "Thread 2 needs: a[0], a[1], a[2]  ← 3 global memory reads\n",
    "Thread 3 needs: a[1], a[2], a[3]  ← 3 global memory reads\n",
    "Thread 4 needs: a[2], a[3], a[4]  ← 3 global memory reads\n",
    "                  ↑    ↑\n",
    "            Same elements read multiple times!\n",
    "\n",
    "With shared memory:\n",
    "1. Each thread loads ONE element to shared (8 global reads total)\n",
    "2. Threads read from FAST shared memory for neighbors\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Execution Trace for Thread 3\n",
    "\n",
    "```\n",
    "local_i = 3\n",
    "\n",
    "Loop iteration j=0: neigh_idx = 3-0 = 3, 3≥0 , val += shared[3]\n",
    "Loop iteration j=1: neigh_idx = 3-1 = 2, 2≥0 , val += shared[2]\n",
    "Loop iteration j=2: neigh_idx = 3-2 = 1, 1≥0 , val += shared[1]\n",
    "\n",
    "val = shared[3] + shared[2] + shared[1]\n",
    "    = a[3] + a[2] + a[1]\n",
    "    = 3 + 2 + 1 = 6\n",
    "\n",
    "out[3] = 6 \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Boundary Handling\n",
    "\n",
    "```\n",
    "Thread 0 (local_i = 0):\n",
    "  j=0: neigh_idx = 0, 0≥0  → val += shared[0]\n",
    "  j=1: neigh_idx = -1, -1≥0  → skip\n",
    "  j=2: neigh_idx = -2, -2≥0  → skip\n",
    "  \n",
    "  Only adds shared[0], correctly handles left boundary!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Neighbor access** - Each thread reads nearby elements\n",
    "2. **Shared memory** - Load once, read multiple times\n",
    "3. **Boundary checks** - Handle edge cases explicitly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e5fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:42.930415Z",
     "iopub.status.busy": "2022-08-07T21:24:42.929976Z",
     "iopub.status.idle": "2022-08-07T21:24:43.020899Z",
     "shell.execute_reply": "2022-08-07T21:24:43.020143Z"
    },
    "id": "f35e5fdb",
    "outputId": "7b251baf-f498-467e-a58e-9e713c2f2bb0"
   },
   "outputs": [],
   "source": [
    "def pool_spec(a):\n",
    "    out = np.zeros(*a.shape)\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = a[max(i - 2, 0) : i + 1].sum()\n",
    "    return out\n",
    "\n",
    "\n",
    "TPB = 8\n",
    "def pool_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        shared = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "\n",
    "        if i < size:\n",
    "            shared[local_i] = a[i]\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        if i < size:\n",
    "            val=0\n",
    "            for j in range(3):\n",
    "                neigh_idx = local_i - j\n",
    "                if neigh_idx >= 0:\n",
    "                    val += shared[neigh_idx]\n",
    "\n",
    "            out[i] = val\n",
    "\n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 8\n",
    "out = np.zeros(SIZE)\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Pooling\",\n",
    "    pool_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(TPB, 1),\n",
    "    blockspergrid=Coord(1, 1),\n",
    "    spec=pool_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac503e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.024701Z",
     "iopub.status.busy": "2022-08-07T21:24:43.024250Z",
     "iopub.status.idle": "2022-08-07T21:24:43.069099Z",
     "shell.execute_reply": "2022-08-07T21:24:43.068252Z"
    },
    "id": "b9ac503e",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "a0d99654-127d-4a87-d257-53a67e518366"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04727aa4",
   "metadata": {
    "id": "04727aa4"
   },
   "source": [
    "## Puzzle 10 - Dot Product\n",
    "\n",
    "Implement a kernel that computes the dot-product of `a` and `b` and stores it in `out`.\n",
    "You have 1 thread per position. You only need 2 global reads and 1 global write per thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63a4c2",
   "metadata": {
    "id": "1a63a4c2"
   },
   "source": [
    "*Note: For this problem you don't need to worry about number of shared reads. We will\n",
    " handle that challenge later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_46",
   "metadata": {},
   "source": [
    "##  Puzzle 10: Dot Product - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Compute dot product: `out = Σ a[i] × b[i]`\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Reduction\n",
    "\n",
    "A reduction combines many values into ONE result. This requires cooperation between threads!\n",
    "\n",
    "```\n",
    "a = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "b = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "Products: [0, 1, 4, 9, 16, 25, 36, 49]\n",
    "Sum:      0+1+4+9+16+25+36+49 = 140\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Two-Phase Execution\n",
    "\n",
    "```\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║ PHASE 1: PARALLEL MULTIPLY                                      ║\n",
    "║ All 8 threads work simultaneously                               ║\n",
    "╠════════════════════════════════════════════════════════════════╣\n",
    "║ T0: shared[0] = 0×0 = 0     T4: shared[4] = 4×4 = 16           ║\n",
    "║ T1: shared[1] = 1×1 = 1     T5: shared[5] = 5×5 = 25           ║\n",
    "║ T2: shared[2] = 2×2 = 4     T6: shared[6] = 6×6 = 36           ║\n",
    "║ T3: shared[3] = 3×3 = 9     T7: shared[7] = 7×7 = 49           ║\n",
    "╠════════════════════════════════════════════════════════════════╣\n",
    "║ syncthreads() - wait for all products                          ║\n",
    "╠════════════════════════════════════════════════════════════════╣\n",
    "║ PHASE 2: SEQUENTIAL SUM (Thread 0 only)                        ║\n",
    "║                                                                 ║\n",
    "║ T0: total = 0+1+4+9+16+25+36+49 = 140                          ║\n",
    "║     out[0] = 140                                                ║\n",
    "║                                                                 ║\n",
    "║ T1-T7: (do nothing, wait)                                      ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Limitation: Sequential Sum\n",
    "\n",
    "This solution uses O(n) time for the sum (single thread).\n",
    "\n",
    "**Better approach: Parallel Reduction** (next puzzle!)\n",
    "- O(log n) time using tree-based summing\n",
    "- All threads participate in reduction\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Map-Reduce pattern**: Parallel multiply, reduce to sum\n",
    "2. **Shared memory**: Stores intermediate products\n",
    "3. **Single thread finishes**: Simple but not optimal for large arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d84c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.073281Z",
     "iopub.status.busy": "2022-08-07T21:24:43.072839Z",
     "iopub.status.idle": "2022-08-07T21:24:43.174688Z",
     "shell.execute_reply": "2022-08-07T21:24:43.173818Z"
    },
    "id": "e5d84c0f",
    "outputId": "af7ac903-c8e1-47f1-d33d-170cb0af43e2"
   },
   "outputs": [],
   "source": [
    "def dot_spec(a, b):\n",
    "    return a @ b\n",
    "\n",
    "TPB = 8\n",
    "def dot_test(cuda):\n",
    "    def call(out, a, b, size) -> None:\n",
    "        shared = cuda.shared.array(TPB, numba.float32)\n",
    "    \n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        \n",
    "        if i < size:\n",
    "            shared[local_i] = a[i]*b[i]\n",
    "        else:\n",
    "            shared[local_i] = 0\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "\n",
    "        if local_i==0:\n",
    "            total=0\n",
    "            for j in range(size):\n",
    "                total += shared[j]\n",
    "\n",
    "            out[0] = total\n",
    "        \n",
    "    return call\n",
    "\n",
    "\n",
    "SIZE = 8\n",
    "out = np.zeros(1)\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Dot\",\n",
    "    dot_test,\n",
    "    [a, b],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(SIZE, 1),\n",
    "    blockspergrid=Coord(1, 1),\n",
    "    spec=dot_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452858a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.178517Z",
     "iopub.status.busy": "2022-08-07T21:24:43.178082Z",
     "iopub.status.idle": "2022-08-07T21:24:43.224369Z",
     "shell.execute_reply": "2022-08-07T21:24:43.223563Z"
    },
    "id": "1452858a",
    "outputId": "29cbcb8b-4a72-44b0-d84d-7f63542a3657"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060685a2",
   "metadata": {
    "id": "060685a2",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Puzzle 11 - 1D Convolution\n",
    "\n",
    "Implement a kernel that computes a 1D convolution between `a` and `b` and stores it in `out`.\n",
    "You need to handle the general case. You only need 2 global reads and 1 global write per thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_49",
   "metadata": {},
   "source": [
    "##  Puzzle 11: 1D Convolution - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Compute 1D convolution: `out[i] = Σ a[i+j] × b[j]`\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Convolution\n",
    "\n",
    "```\n",
    "Input a:  [0, 1, 2, 3, 4, 5]\n",
    "Kernel b: [0, 1, 2]\n",
    "\n",
    "out[0] = a[0]×b[0] + a[1]×b[1] + a[2]×b[2] = 0×0 + 1×1 + 2×2 = 5\n",
    "out[1] = a[1]×b[0] + a[2]×b[1] + a[3]×b[2] = 1×0 + 2×1 + 3×2 = 8\n",
    "out[2] = a[2]×b[0] + a[3]×b[1] + a[4]×b[2] = 2×0 + 3×1 + 4×2 = 11\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Understanding the Halo Region\n",
    "\n",
    "```\n",
    "Block handles indices 0-7 (TPB=8), kernel size 3\n",
    "\n",
    "Thread 7 needs: a[7], a[8], a[9]\n",
    "                       ↑    ↑\n",
    "                    BEYOND block's main region!\n",
    "\n",
    "shared_a layout (size TPB + MAX_CONV = 12):\n",
    "┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐\n",
    "│a0 │a1 │a2 │a3 │a4 │a5 │a6 │a7 │a8 │a9 │ 0 │ 0 │\n",
    "└───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘\n",
    " └────────── Main (TPB=8) ──────────┘└ Halo ─┘\n",
    "\n",
    "Halo = extra elements at the end needed for convolution\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Halo Loading Logic\n",
    "\n",
    "```python\n",
    "if local_i < b_size - 1:           # Only first kernel_size-1 threads\n",
    "    if i + TPB < a_size:           # If element exists\n",
    "        shared_a[local_i + TPB] = a[i + TPB]\n",
    "\n",
    "For kernel size 3, threads 0 and 1 load the halo:\n",
    "  Thread 0: shared_a[8] = a[8]\n",
    "  Thread 1: shared_a[9] = a[9]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Halo region**: Extra elements beyond block boundary\n",
    "2. **Halo size**: kernel_size - 1\n",
    "3. **Shared memory size**: TPB + halo\n",
    "4. **Only some threads load halo**: First (kernel_size - 1) threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311eeeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.228540Z",
     "iopub.status.busy": "2022-08-07T21:24:43.228045Z",
     "iopub.status.idle": "2022-08-07T21:24:43.325332Z",
     "shell.execute_reply": "2022-08-07T21:24:43.324481Z"
    },
    "id": "d311eeeb",
    "outputId": "da64052e-a3a5-4492-d881-492d9f4c3be8"
   },
   "outputs": [],
   "source": [
    "def conv_spec(a, b):\n",
    "    out = np.zeros(*a.shape)\n",
    "    len = b.shape[0]\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = sum([a[i + j] * b[j] for j in range(len) if i + j < a.shape[0]])\n",
    "    return out\n",
    "\n",
    "\n",
    "MAX_CONV = 4\n",
    "TPB = 8\n",
    "TPB_MAX_CONV = TPB + MAX_CONV\n",
    "def conv_test(cuda):\n",
    "    def call(out, a, b, a_size, b_size) -> None:\n",
    "        shared_a = cuda.shared.array(TPB_MAX_CONV, numba.float32)\n",
    "        shared_b = cuda.shared.array(MAX_CONV, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "\n",
    "        if i < a_size:\n",
    "            shared_a[local_i] = a[i]\n",
    "        else:\n",
    "            shared_a[local_i] = 0\n",
    "            \n",
    "        if local_i < MAX_CONV:\n",
    "            if local_i < b_size:\n",
    "                shared_b[local_i] = b[local_i]\n",
    "            else:\n",
    "                shared_b[local_i] = 0\n",
    "\n",
    "        if local_i < b_size - 1:\n",
    "            if i + TPB < a_size:\n",
    "                shared_a[local_i + TPB] = a[i + TPB]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        if i < a_size:\n",
    "            tmp=0.0\n",
    "            for j in range(b_size):\n",
    "                if i + j < a_size:\n",
    "                    tmp += shared_a[local_i + j]*shared_b[j]\n",
    "\n",
    "            out[i] = tmp\n",
    "        \n",
    "    return call\n",
    "\n",
    "\n",
    "# Test 1\n",
    "\n",
    "SIZE = 6\n",
    "CONV = 3\n",
    "out = np.zeros(SIZE)\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(CONV)\n",
    "problem = CudaProblem(\n",
    "    \"1D Conv (Simple)\",\n",
    "    conv_test,\n",
    "    [a, b],\n",
    "    out,\n",
    "    [SIZE, CONV],\n",
    "    Coord(1, 1),\n",
    "    Coord(TPB, 1),\n",
    "    spec=conv_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb88cd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.329452Z",
     "iopub.status.busy": "2022-08-07T21:24:43.328685Z",
     "iopub.status.idle": "2022-08-07T21:24:43.368279Z",
     "shell.execute_reply": "2022-08-07T21:24:43.367480Z"
    },
    "id": "ffb88cd0",
    "outputId": "ccd7ace0-7029-4c21-d6d1-0950a15c0518"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ffcb3",
   "metadata": {
    "id": "fd6ffcb3"
   },
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60853445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.372330Z",
     "iopub.status.busy": "2022-08-07T21:24:43.371893Z",
     "iopub.status.idle": "2022-08-07T21:24:43.587696Z",
     "shell.execute_reply": "2022-08-07T21:24:43.586874Z"
    },
    "id": "60853445",
    "outputId": "bea21765-f707-4f3f-8f9b-42c5c7ba4af2"
   },
   "outputs": [],
   "source": [
    "out = np.zeros(15)\n",
    "a = np.arange(15)\n",
    "b = np.arange(4)\n",
    "problem = CudaProblem(\n",
    "    \"1D Conv (Full)\",\n",
    "    conv_test,\n",
    "    [a, b],\n",
    "    out,\n",
    "    [15, 4],\n",
    "    Coord(2, 1),\n",
    "    Coord(TPB, 1),\n",
    "    spec=conv_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a29f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.592341Z",
     "iopub.status.busy": "2022-08-07T21:24:43.591898Z",
     "iopub.status.idle": "2022-08-07T21:24:43.632088Z",
     "shell.execute_reply": "2022-08-07T21:24:43.631270Z"
    },
    "id": "80a29f20",
    "outputId": "c9c6294c-715f-4afc-f88f-56ac000514de"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f53d7",
   "metadata": {
    "id": "2d5f53d7"
   },
   "source": [
    "## Puzzle 12 - Prefix Sum\n",
    "\n",
    "Implement a kernel that computes a sum over `a` and stores it in `out`.\n",
    "If the size of `a` is greater than the block size, only store the sum of\n",
    "each block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41aec0",
   "metadata": {
    "id": "2e41aec0"
   },
   "source": [
    "We will do this using the [parallel prefix sum](https://en.wikipedia.org/wiki/Prefix_sum) algorithm in shared memory.\n",
    "That is, each step of the algorithm should sum together half the remaining numbers.\n",
    "Follow this diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a47dd",
   "metadata": {
    "id": "9c6a47dd"
   },
   "source": [
    "![](https://user-images.githubusercontent.com/35882/178757889-1c269623-93af-4a2e-a7e9-22cd55a42e38.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_57",
   "metadata": {},
   "source": [
    "##  Puzzle 12: Sum Reduction - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Sum all elements using PARALLEL reduction - O(log n) instead of O(n)!\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Tree Reduction\n",
    "\n",
    "```\n",
    "Sequential sum: 8 steps for 8 elements\n",
    "Parallel reduction: 3 steps for 8 elements (log₂8 = 3)\n",
    "\n",
    "Step 1:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "           ↓  ↓  ↓  ↓\n",
    "          4 threads add pairs at stride 4:\n",
    "          cache[0]+=cache[4], cache[1]+=cache[5], ...\n",
    "Result:  [4, 6, 8, 10, -, -, -, -]\n",
    "\n",
    "Step 2:  [4, 6, 8, 10, -, -, -, -]\n",
    "           ↓  ↓\n",
    "          2 threads add pairs at stride 2:\n",
    "Result:  [12, 16, -, -, -, -, -, -]\n",
    "\n",
    "Step 3:  [12, 16, -, -, -, -, -, -]\n",
    "            ↓\n",
    "          1 thread adds pair at stride 1:\n",
    "Result:  [28, -, -, -, -, -, -, -]\n",
    "\n",
    "Final sum: 28 = 0+1+2+3+4+5+6+7 \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Step-by-Step Execution\n",
    "\n",
    "```\n",
    "Initial cache: [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║ STRIDE = 4                                                         ║\n",
    "║ Active threads: 0, 1, 2, 3 (local_i < 4)                          ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ T0: cache[0] += cache[4]  →  0 + 4 = 4                            ║\n",
    "║ T1: cache[1] += cache[5]  →  1 + 5 = 6                            ║\n",
    "║ T2: cache[2] += cache[6]  →  2 + 6 = 8                            ║\n",
    "║ T3: cache[3] += cache[7]  →  3 + 7 = 10                           ║\n",
    "║                                                                    ║\n",
    "║ cache: [4, 6, 8, 10, 4, 5, 6, 7]                                  ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ syncthreads(), stride = 2                                         ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ STRIDE = 2                                                         ║\n",
    "║ Active threads: 0, 1 (local_i < 2)                                ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ T0: cache[0] += cache[2]  →  4 + 8 = 12                           ║\n",
    "║ T1: cache[1] += cache[3]  →  6 + 10 = 16                          ║\n",
    "║                                                                    ║\n",
    "║ cache: [12, 16, 8, 10, 4, 5, 6, 7]                                ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ syncthreads(), stride = 1                                         ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ STRIDE = 1                                                         ║\n",
    "║ Active threads: 0 only (local_i < 1)                              ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ T0: cache[0] += cache[1]  →  12 + 16 = 28                         ║\n",
    "║                                                                    ║\n",
    "║ cache: [28, 16, 8, 10, 4, 5, 6, 7]                                ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║ stride = 0, exit loop                                              ║\n",
    "║ out[blockIdx.x] = cache[0] = 28                                   ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Performance: O(log n) vs O(n)\n",
    "\n",
    "```\n",
    "For n = 1024 elements:\n",
    "  Sequential: 1024 additions (by one thread)\n",
    "  Parallel:   10 steps (log₂1024 = 10), using 512→256→...→1 threads\n",
    "\n",
    "For n = 1,000,000:\n",
    "  Sequential: 1,000,000 steps\n",
    "  Parallel:   20 steps!  (~50,000x faster conceptually)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Halving stride**: `stride //= 2` each iteration\n",
    "2. **Halving active threads**: `if local_i < stride`\n",
    "3. **O(log n) steps**: Maximum parallelism utilization\n",
    "4. **syncthreads in loop**: Essential for correctness!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a0a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.636349Z",
     "iopub.status.busy": "2022-08-07T21:24:43.635880Z",
     "iopub.status.idle": "2022-08-07T21:24:43.714064Z",
     "shell.execute_reply": "2022-08-07T21:24:43.713293Z"
    },
    "id": "130a0a8d",
    "outputId": "3c44f749-908f-4c18-a48b-0de2a24e4143"
   },
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def sum_spec(a):\n",
    "    out = np.zeros((a.shape[0] + TPB - 1) // TPB)\n",
    "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
    "        out[j] = a[i : i + TPB].sum()\n",
    "    return out\n",
    "\n",
    "\n",
    "def sum_test(cuda):\n",
    "    def call(out, a, size: int) -> None:\n",
    "        cache = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        \n",
    "        if i < size:\n",
    "            cache[local_i] = a[i]\n",
    "        else:\n",
    "            cache[local_i] = 0.0\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        stride = cuda.blockDim.x // 2\n",
    "        while stride > 0 :\n",
    "            if local_i < stride:\n",
    "                cache[local_i] += cache[local_i + stride]\n",
    "\n",
    "            stride //= 2\n",
    "            cuda.syncthreads()\n",
    "\n",
    "\n",
    "        if local_i == 0:\n",
    "            out[cuda.blockIdx.x] = cache[0]\n",
    "        \n",
    "\n",
    "    return call\n",
    "\n",
    "# Test 1\n",
    "\n",
    "SIZE = 8\n",
    "out = np.zeros(1)\n",
    "inp = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Sum (Simple)\",\n",
    "    sum_test,\n",
    "    [inp],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    Coord(1, 1),\n",
    "    Coord(TPB, 1),\n",
    "    spec=sum_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.717874Z",
     "iopub.status.busy": "2022-08-07T21:24:43.717439Z",
     "iopub.status.idle": "2022-08-07T21:24:43.762084Z",
     "shell.execute_reply": "2022-08-07T21:24:43.761264Z"
    },
    "id": "e03a0c71",
    "outputId": "42998104-3cdd-42f8-903e-980da7961bc1"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd86af0",
   "metadata": {
    "id": "ccd86af0"
   },
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b021a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.766261Z",
     "iopub.status.busy": "2022-08-07T21:24:43.765816Z",
     "iopub.status.idle": "2022-08-07T21:24:43.906583Z",
     "shell.execute_reply": "2022-08-07T21:24:43.905757Z"
    },
    "id": "89b021a9",
    "outputId": "dab048de-8616-4f2c-8900-0a2078aca559"
   },
   "outputs": [],
   "source": [
    "SIZE = 15\n",
    "out = np.zeros(2)\n",
    "inp = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Sum (Full)\",\n",
    "    sum_test,\n",
    "    [inp],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    Coord(2, 1),\n",
    "    Coord(TPB, 1),\n",
    "    spec=sum_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dad418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.910655Z",
     "iopub.status.busy": "2022-08-07T21:24:43.910219Z",
     "iopub.status.idle": "2022-08-07T21:24:43.955778Z",
     "shell.execute_reply": "2022-08-07T21:24:43.954979Z"
    },
    "id": "16dad418",
    "outputId": "622d8a98-cff3-4c71-a758-5cc29414e38a"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cpu_block_sum(a, TPB):\n",
    "    # Calculate how many blocks we will have\n",
    "    num_blocks = (len(a) + TPB - 1) // TPB\n",
    "    out = np.zeros(num_blocks)\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        # Extract the segment (block)\n",
    "        start = i * TPB\n",
    "        end = start + TPB\n",
    "        segment = a[start:end]\n",
    "        \n",
    "        # Sum the segment and store it\n",
    "        out[i] = sum(segment)\n",
    "        \n",
    "    return out\n",
    "\n",
    "# Example usage:\n",
    "inp = np.arange(15)\n",
    "tpb = 8\n",
    "print(\"1D Block Sum:\", cpu_block_sum(inp, tpb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162146c3",
   "metadata": {
    "id": "162146c3"
   },
   "source": [
    "## Puzzle 13 - Axis Sum\n",
    "\n",
    "Implement a kernel that computes a sum over each column of `a` and stores it in `out`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_64",
   "metadata": {},
   "source": [
    "##  Puzzle 13: Axis Sum - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Sum along the last axis of a 2D matrix - each row reduced independently.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Batched Reduction\n",
    "\n",
    "```\n",
    "Input (4×6):                    Output (4×1):\n",
    "Row 0: [0,  1,  2,  3,  4,  5]  →  sum = 15\n",
    "Row 1: [6,  7,  8,  9, 10, 11]  →  sum = 51\n",
    "Row 2: [12,13, 14, 15, 16, 17]  →  sum = 87\n",
    "Row 3: [18,19, 20, 21, 22, 23]  →  sum = 123\n",
    "\n",
    "Each row is an INDEPENDENT reduction!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Block Assignment\n",
    "\n",
    "```\n",
    "blockspergrid = (1, BATCH) = (1, 4)\n",
    "\n",
    "4 blocks, each handling one row:\n",
    "\n",
    "Block (0, 0): batch=0, handles row 0, outputs to out[0, 0]\n",
    "Block (0, 1): batch=1, handles row 1, outputs to out[1, 0]\n",
    "Block (0, 2): batch=2, handles row 2, outputs to out[2, 0]\n",
    "Block (0, 3): batch=3, handles row 3, outputs to out[3, 0]\n",
    "\n",
    "All 4 blocks run in PARALLEL - 4 reductions at once!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Line: Using blockIdx.y for Batch\n",
    "\n",
    "```python\n",
    "batch = cuda.blockIdx.y\n",
    "\n",
    "cache[local_i] = a[batch, i]      # Different row per block\n",
    "out[batch, cuda.blockIdx.x] = ... # Different output row per block\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **blockIdx.y as batch index** - Different rows = different blocks\n",
    "2. **Same reduction code** - Just parameterized by batch\n",
    "3. **Rows are independent** - No inter-block communication needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fd5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:43.959820Z",
     "iopub.status.busy": "2022-08-07T21:24:43.959380Z",
     "iopub.status.idle": "2022-08-07T21:24:44.280640Z",
     "shell.execute_reply": "2022-08-07T21:24:44.279832Z"
    },
    "id": "e87fd5df",
    "outputId": "0e8d0fa6-e1a1-4f69-d682-041f4c085d4c"
   },
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def sum_spec(a):\n",
    "    out = np.zeros((a.shape[0], (a.shape[1] + TPB - 1) // TPB))\n",
    "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
    "        out[..., j] = a[..., i : i + TPB].sum(-1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def axis_sum_test(cuda):\n",
    "    def call(out, a, size: int) -> None:\n",
    "        cache = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        batch = cuda.blockIdx.y\n",
    "\n",
    "        if i < size:\n",
    "            cache[local_i] = a[batch, i]\n",
    "        else:\n",
    "            cache[local_i] = 0.0\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "\n",
    "        stride = cuda.blockDim.x // 2\n",
    "        while stride > 0 :\n",
    "            if local_i < stride:\n",
    "                cache[local_i] += cache[local_i + stride]\n",
    "\n",
    "            stride //= 2\n",
    "            cuda.syncthreads()\n",
    "\n",
    "            if local_i == 0:\n",
    "                out[batch, cuda.blockIdx.x] = cache[0]\n",
    "\n",
    "    return call\n",
    "\n",
    "\n",
    "BATCH = 4\n",
    "SIZE = 6\n",
    "out = np.zeros((BATCH, 1))\n",
    "inp = np.arange(BATCH * SIZE).reshape((BATCH, SIZE))\n",
    "problem = CudaProblem(\n",
    "    \"Axis Sum\",\n",
    "    axis_sum_test,\n",
    "    [inp],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    Coord(1, BATCH),\n",
    "    Coord(TPB, 1),\n",
    "    spec=sum_spec,\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3326563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:44.289173Z",
     "iopub.status.busy": "2022-08-07T21:24:44.288667Z",
     "iopub.status.idle": "2022-08-07T21:24:44.336305Z",
     "shell.execute_reply": "2022-08-07T21:24:44.335469Z"
    },
    "id": "c3326563",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1,
    "outputId": "cc93a240-b89c-41d0-ba9c-8c5e91c91050"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_axis_sum(a, TPB):\n",
    "    batch_size = a.shape[0]\n",
    "    num_columns = a.shape[1]\n",
    "    num_blocks = (num_columns + TPB - 1) // TPB\n",
    "    \n",
    "    # Initialize output matrix\n",
    "    out = np.zeros((batch_size, num_blocks))\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        for i in range(num_blocks):\n",
    "            start = i * TPB\n",
    "            end = start + TPB\n",
    "            \n",
    "            # Sum the segment of the specific row 'b'\n",
    "            segment = a[b, start:end]\n",
    "            out[b, i] = sum(segment)\n",
    "            \n",
    "    return out\n",
    "\n",
    "# Example usage:\n",
    "BATCH, SIZE = 2, 6\n",
    "inp_2d = np.arange(BATCH * SIZE).reshape((BATCH, SIZE))\n",
    "print(\"2D Axis Sum:\\n\", cpu_axis_sum(inp_2d, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300312e8",
   "metadata": {
    "id": "300312e8"
   },
   "source": [
    "## Puzzle 14 - Matrix Multiply!\n",
    "\n",
    "Implement a kernel that multiplies square matrices `a` and `b` and\n",
    "stores the result in `out`.\n",
    "\n",
    "*Tip: The most efficient algorithm here will copy a block into\n",
    " shared memory before computing each of the individual row-column\n",
    " dot products. This is easy to do if the matrix fits in shared\n",
    " memory.  Do that case first. Then update your code to compute\n",
    " a partial dot-product and iteratively move the part you\n",
    " copied into shared memory.* You should be able to do the hard case\n",
    " in 6 global reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_68",
   "metadata": {},
   "source": [
    "##  Puzzle 14: Matrix Multiplication - Deep Dive Solution Explanation\n",
    "\n",
    "---\n",
    "\n",
    "###  Problem Statement\n",
    "Compute C = A × B using tiled matrix multiplication with shared memory.\n",
    "\n",
    "---\n",
    "\n",
    "###  Core Concept: Tiled Matrix Multiplication\n",
    "\n",
    "**The Problem with Naive Matmul:**\n",
    "```\n",
    "For each C[i,j]: Load entire row of A, entire column of B\n",
    "For N×N matrices: N³ global memory reads!\n",
    "\n",
    "Tiled approach: Load small tiles, reuse from shared memory\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  The Tiling Strategy\n",
    "\n",
    "```\n",
    "For C[i,j] = Σₖ A[i,k] × B[k,j]\n",
    "\n",
    "Instead of loading entire row/column:\n",
    "1. Load TPB×TPB tile of A (around row i)\n",
    "2. Load TPB×TPB tile of B (around column j)\n",
    "3. Compute partial products\n",
    "4. Move to next tile, repeat\n",
    "5. Accumulate all partial products\n",
    "\n",
    "Tiles slide along the K dimension:\n",
    "\n",
    "    A                    B                    C\n",
    "┌───────────────┐   ┌───────────────┐   ┌───────────┐\n",
    "│ T0 │ T1 │ T2 │   │ T0 │          │   │           │\n",
    "├────┼────┼────┤   ├────┤          │   │   C[i,j]  │\n",
    "│    │    │    │   │ T1 │          │   │     =     │\n",
    "├────┼────┼────┤   ├────┤          │   │  Σ tiles  │\n",
    "│    │    │    │   │ T2 │          │   │           │\n",
    "└───────────────┘   └───────────────┘   └───────────┘\n",
    "  ↑ Row i tiles       ↑ Column j tiles\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Execution for One Output Element\n",
    "\n",
    "```\n",
    "Thread at (i=0, j=0) computing C[0,0]:\n",
    "\n",
    "Tile 0:\n",
    "  Load A[0, 0:3] into a_shared[0, :]\n",
    "  Load B[0:3, 0] into b_shared[:, 0]\n",
    "  tmp += a_shared[0,0]*b_shared[0,0]\n",
    "       + a_shared[0,1]*b_shared[1,0]\n",
    "       + a_shared[0,2]*b_shared[2,0]\n",
    "\n",
    "Tile 1:\n",
    "  Load A[0, 3:6] into a_shared[0, :]\n",
    "  Load B[3:6, 0] into b_shared[:, 0]\n",
    "  tmp += a_shared[0,0]*b_shared[0,0]\n",
    "       + a_shared[0,1]*b_shared[1,0]\n",
    "       + a_shared[0,2]*b_shared[2,0]\n",
    "\n",
    "... continue for all tiles ...\n",
    "\n",
    "C[0,0] = tmp (complete dot product)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Why Tiling Is Efficient\n",
    "\n",
    "```\n",
    "Naive: For N×N matmul\n",
    "  Each element needs 2N global reads\n",
    "  Total: 2N³ global memory accesses\n",
    "\n",
    "Tiled (tile size T):\n",
    "  Each tile loaded once, used T times\n",
    "  Total: 2N³/T global memory accesses\n",
    "  \n",
    "For T=32: 32x reduction in memory traffic!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "1. **Tiles slide along K dimension** - Partial products accumulate\n",
    "2. **Load cooperatively** - Each thread loads one element of each tile\n",
    "3. **Compute locally** - Multiply from shared memory (fast!)\n",
    "4. **Two syncthreads()** - After load AND after compute\n",
    "5. **This is how cuBLAS works** - Fundamental GPU optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252db1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:44.340330Z",
     "iopub.status.busy": "2022-08-07T21:24:44.339875Z",
     "iopub.status.idle": "2022-08-07T21:24:44.433833Z",
     "shell.execute_reply": "2022-08-07T21:24:44.433028Z"
    },
    "id": "252db1c3",
    "outputId": "c95b4858-b144-4708-e20a-d972bdd9780f"
   },
   "outputs": [],
   "source": [
    "def matmul_spec(a, b):\n",
    "    return a @ b\n",
    "\n",
    "\n",
    "TPB = 3\n",
    "def mm_oneblock_test(cuda):\n",
    "    def call(out, a, b, size: int) -> None:\n",
    "        a_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
    "        b_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
    "\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "\n",
    "        tmp=0.0\n",
    "        for tile_idx in range((size + TPB - 1)//TPB):\n",
    "        \n",
    "            if i < size and (tile_idx * TPB + local_j) < size:\n",
    "                a_shared[local_i, local_j] = a[i, tile_idx*TPB + local_j]\n",
    "            else:\n",
    "                a_shared[local_i, local_j] = 0\n",
    "\n",
    "            \n",
    "            if j < size and (tile_idx * TPB + local_i) < size:\n",
    "                b_shared[local_i, local_j] = b[tile_idx*TPB + local_i, j]\n",
    "            else:\n",
    "                b_shared[local_i, local_j] = 0\n",
    "\n",
    "            cuda.syncthreads()\n",
    "\n",
    "            for k in range(TPB):\n",
    "                tmp += a_shared[local_i, k]*b_shared[k, local_j]\n",
    "\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        if i < size and j < size:\n",
    "            out[i, j] = tmp\n",
    "\n",
    "    return call\n",
    "\n",
    "# Test 1\n",
    "\n",
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T\n",
    "\n",
    "problem = CudaProblem(\n",
    "    \"Matmul (Simple)\",\n",
    "    mm_oneblock_test,\n",
    "    [inp1, inp2],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    Coord(1, 1),\n",
    "    Coord(TPB, TPB),\n",
    "    spec=matmul_spec,\n",
    ")\n",
    "problem.show(sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb812973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:44.437576Z",
     "iopub.status.busy": "2022-08-07T21:24:44.437142Z",
     "iopub.status.idle": "2022-08-07T21:24:44.502001Z",
     "shell.execute_reply": "2022-08-07T21:24:44.501163Z"
    },
    "id": "cb812973",
    "outputId": "6d064d7b-c576-4230-b51d-1396bf606f42"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119be2d",
   "metadata": {
    "id": "f119be2d"
   },
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713d056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:44.506178Z",
     "iopub.status.busy": "2022-08-07T21:24:44.505708Z",
     "iopub.status.idle": "2022-08-07T21:24:47.932059Z",
     "shell.execute_reply": "2022-08-07T21:24:47.931153Z"
    },
    "id": "e713d056",
    "outputId": "5765452c-3f52-4293-cd0f-9e4b01f3751f"
   },
   "outputs": [],
   "source": [
    "SIZE = 8\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T\n",
    "\n",
    "problem = CudaProblem(\n",
    "    \"Matmul (Full)\",\n",
    "    mm_oneblock_test,\n",
    "    [inp1, inp2],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    Coord(3, 3),\n",
    "    Coord(TPB, TPB),\n",
    "    spec=matmul_spec,\n",
    ")\n",
    "problem.show(sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bda17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T21:24:47.956298Z",
     "iopub.status.busy": "2022-08-07T21:24:47.955822Z",
     "iopub.status.idle": "2022-08-07T21:24:48.019620Z",
     "shell.execute_reply": "2022-08-07T21:24:48.018792Z"
    },
    "id": "61bda17c",
    "outputId": "c50b7745-f7d5-409b-86f7-f759950dbef1"
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f110e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_matmul(a, b, TPB=8):\n",
    "    c=np.zeros((a.shape[0], b.shape[1]))\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(b.shape[1]):\n",
    "            for k in range(a.shape[1]):\n",
    "                c[i, j] += a[i, k]*b[k, j]\n",
    "    return c\n",
    "\n",
    "\n",
    "a=np.array([[1,1], [2,3]])\n",
    "b = np.array([[1,2,3,], [3,4,5]])\n",
    "\n",
    "\n",
    "print(cpu_matmul(a,b))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
